# ──────────────────────────────────────────────
# Required (only when using the corresponding provider)
# ──────────────────────────────────────────────

# Anthropic API key for Claude chat responses (required when CHAT_PROVIDER=anthropic)
ANTHROPIC_API_KEY=your-anthropic-api-key

# Supabase project URL and service role key (for pgvector storage)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# ──────────────────────────────────────────────
# Optional — defaults shown
# ──────────────────────────────────────────────

# Embedding provider: "ollama" (local, default) or "openai"
# EMBEDDING_PROVIDER=ollama

# Required only if EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Ollama settings (used when EMBEDDING_PROVIDER=ollama)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Chunking
# CHUNK_SIZE=500
# CHUNK_OVERLAP=100

# Vector store
# UPSERT_BATCH_SIZE=100
# MATCH_THRESHOLD=0.5
# TOP_K=5

# Chat provider: "ollama" (local, default) or "anthropic"
# CHAT_PROVIDER=ollama

# Ollama chat model (used when CHAT_PROVIDER=ollama)
# OLLAMA_CHAT_MODEL=llama3.2

# Anthropic chat model (used when CHAT_PROVIDER=anthropic)
# CHAT_MODEL=claude-sonnet-4-20250514
# CHAT_MAX_TOKENS=1024
# CHAT_MAX_MESSAGE_LENGTH=2000
# CHAT_MAX_HISTORY=50

# Rate limiting
# RATE_LIMIT_WINDOW_MS=60000
# RATE_LIMIT_MAX_REQUESTS=10

# ──────────────────────────────────────────────
# LocalStack / AWS Local Development
# ──────────────────────────────────────────────

# Set to "true" to route AWS SDK calls to LocalStack
# USE_LOCALSTACK=true
# LOCALSTACK_ENDPOINT=http://localhost:4566
# AWS_REGION=us-east-1

# Local PostgreSQL (used with LocalStack instead of RDS)
# DB_HOST=localhost
# DB_PORT=5432
# DB_USER=chatdev
# DB_PASSWORD=localdev123
# DB_NAME=portfolio_chat
